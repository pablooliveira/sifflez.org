<h1>dataflow.bib</h1><a name="Oliveira12DSL"></a><pre>
@inbook{<a href="/publications/#Oliveira12DSL">Oliveira12DSL</a>,
  author = {de Oliveira Castro, Pablo and Louise, Stéphane and Barthou, Denis},
  publisher = {John Wiley \& Sons, Ltd},
  isbn = {9781119332015},
  title = {DSL Stream Programming on Multicore Architectures},
  booktitle = {Programming multi‐core and many‐core computing systems},
  chapter = {7},
  pages = {143-163},
  doi = {https://doi.org/10.1002/9781119332015.ch7},
  url = {https://hal.science/hal-00952318/document},
  year = {2017},
  keywords = {Array-OL programs, Block Parallel, data dependencies, data parallelism, DSL stream programming, intermediary stream language programs, multicore architectures, pipeline parallelism, SLICES, StreamIt},
  abstract = {Summary The challenge for stream programming on multicore architectures is to describe stream manipulation, dependent on the application, and adapt this stream to complex and changing multicore architectures. Stream languages are a powerful alternative to program multicore processors for two main reasons: they offer a deterministic execution based on a sound mathematical formalism - synchronous data flow (SDF) and the expression of the parallelism is implicitly described by the stream structure. So far, research efforts in stream-specific languages have focused on two language categories: languages such as Array-OL and Block Parallel describe streams through dependences between filters, and languages such as StreamIt and Brook explicitly manipulate stream operators. A high-level typed DSL, called SLICES, is used to describe the data dependencies. This chapter introduces a formal framework for building correct transformations of intermediary stream language (SJD) programs and an iterative exploration algorithm to optimize a program according to a metric.}
}
</pre>

<a name="Oliveira2010automatic"></a><pre>
@inproceedings{<a href="/publications/#Oliveira2010automatic">Oliveira2010automatic</a>,
  title = {Automatic mapping of stream programs on multicore architectures},
  author = {de Oliveira Castro, Pablo and Louise, St\'ephane and Barthou, Denis},
  booktitle = {International Workshop on Compilers for Parallel Computers},
  year = {2010}
}
</pre>

<a name="Oliveira10multidimensional"></a><pre>
@conference{<a href="/publications/#Oliveira10multidimensional">Oliveira10multidimensional</a>,
  pdf = {mucocos10.pdf},
  author = {de Oliveira Castro, Pablo and Louise, St\'ephane and Barthou, Denis},
  title = {{A Multidimensional Array Slicing DSL for Stream Programming}},
  booktitle = {Complex, Intelligent and Software Intensive Systems, International Conference},
  year = {2010},
  pages = {913-918},
  doi = {<a href="http://doi.ieeecomputersociety.org/10.1109/CISIS.2010.135">http://doi.ieeecomputersociety.org/10.1109/CISIS.2010.135</a>},
  publisher = {IEEE Computer Society},
  abstract = {{
Stream languages offer a simple multi-core programming model and achieve good performance. Yet expressing data rearrangement patterns (like a matrix block decomposition) in these languages is verbose and error prone. In this paper, we propose a high-level programming language to elegantly describe n-dimensional data reorganization patterns. We show how to compile it to stream languages.
}}
}
</pre>

<a name="Oliveira10Reducing"></a><pre>
@conference{<a href="/publications/#Oliveira10Reducing">Oliveira10Reducing</a>,
  pdf = {streammemory-hpcs10.pdf},
  title = {{Reducing memory requirements of stream programs by graph transformations}},
  author = {de Oliveira Castro, Pablo and Louise, St\'ephane and Barthou, Denis},
  booktitle = {High Performance Computing and Simulation (HPCS), 2010 International Conference on},
  pages = {171--180},
  year = {2010},
  publisher = {IEEE Computer Society},
  doi = {<a href="http://doi.ieeecomputersociety.org/10.1109/HPCS.2010.5547134">http://doi.ieeecomputersociety.org/10.1109/HPCS.2010.5547134</a>},
  abstract = {{
  Stream languages explicitly describe fork-join parallelism and pipelines, offering a powerful programming model for many-core Multi-Processor Systems on Chip (MPSoC). In an embedded resource-constrained system, adapting stream programs to fit memory requirements is particularly important. In this paper we present a new approach to reduce the memory footprint required to run stream programs on MPSoC. Through an exploration of equivalent program variants, the method selects parallel code minimizing memory consumption. For large program instances, a heuristic accelerating the exploration phase is proposed and evaluated. We demonstrate the interest of our method on a panel of ten significant benchmarks. Using a multi-core modulo scheduling technique, our approach lowers considerably the minimal amount of memory required to run seven of these benchmarks while preserving throughput.
  }}
}
</pre>

<a name="DEOLIVEIRACASTRO:2009:HAL-00447376:1"></a><pre>
@unpublished{<a href="/publications/#DEOLIVEIRACASTRO:2009:HAL-00447376:1">DEOLIVEIRACASTRO:2009:HAL-00447376:1</a>,
  hal_id = {hal-00447376},
  pdf = {<a href="http://hal.archives-ouvertes.fr/hal-00447376/PDF/stream_transformations_hal.pdf">http://hal.archives-ouvertes.fr/hal-00447376/PDF/stream_transformations_hal.pdf</a>},
  title = { {D}esign-{S}pace {E}xploration of {S}tream {P}rograms through {S}emantic-{P}reserving {T}ransformations},
  author = {de Oliveira Castro, Pablo and Louise, St\'ephane and Barthou, Denis},
  abstract = {{S}tream languages explicitly describe fork-join parallelism and pipelines, offering a powerful programming model for many-core {M}ulti-{P}rocessor {S}ystems on {C}hip ({MPS}o{C}). {I}n an embedded resource-constrained system, adapting stream programs to fit memory requirements is particularly important. {I}n this paper we present a design-space exploration technique to reduce the minimal memory required when running stream programs on {MPS}o{C}; this allows to target memory constrained systems and in some cases obtain better performance. {U}sing a set of semantically preserving transformations, we explore a large number of equivalent program variants; we select the variant that minimizes a buffer evaluation metric. {T}o cope efficiently with large program instances we propose and evaluate an heuristic for this method. {W}e demonstrate the interest of our method on a panel of ten significant benchmarks. {A}s an illustration, we measure the minimal memory required using a multi-core modulo scheduling. {O}ur approach lowers considerably the minimal memory required for seven of the ten benchmarks.}
}
</pre>

<a name="Oliveira:phd"></a><pre>
@phdthesis{<a href="/publications/#Oliveira:phd">Oliveira:phd</a>,
  pdf = {these-oliveira.pdf},
  documenturl = {soutenance.pdf},
  title = {{Expression et optimisation des r\'eorganisations de donn\'ees dans du
  parall\'elisme de flots}},
  author = {de Oliveira Castro, Pablo},
  year = {2010},
  school = {Universit\'e de Versailles Saint Quentin en Yvelines}
}
</pre>

